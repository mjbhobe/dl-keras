{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection with Keras\n",
    "In this example, we will write a Keras model to classify messages as Spam or Ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import sys, os, random, pathlib, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED);\n",
    "\n",
    "print(f\"Using Tensorflow {tf.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "We will use the `SMS Spam Collection` dataset, available at UCI archives at the following URL `https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip`. We will use `tf.keras.utils.get_file(...)` to download the dataset to the `./data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
    "DEST_FOLDER = pathlib.Path(os.getcwd()) / \"data\" / \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to /home/mjbhobe/.keras/datasets/smsspamcollection.zip\n",
      "Archive:  /home/mjbhobe/.keras/datasets/smsspamcollection.zip\n",
      "replace /home/mjbhobe/code/git-projects/dl-keras/data/spam/SMSSpamCollection? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "DEST_FOLDER.mkdir(exist_ok=True)\n",
    "path_to_zip = tf.keras.utils.get_file(\"smsspamcollection.zip\", origin=DATASET_URL, extract=True)\n",
    "print(f\"Dataset downloaded to {path_to_zip}\")\n",
    "\n",
    "!unzip $path_to_zip -d $DEST_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 'ham\\tOk lar... Joking wif u oni...',\n",
       " \"spam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       " 'ham\\tU dun say so early hor... U c already then say...',\n",
       " \"ham\\tNah I don't think he goes to usf, he lives around here though\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if we can read the data file\n",
    "lines = io.open(str(DEST_FOLDER / \"SMSSpamCollection\")).read().strip().split(\"\\n\")\n",
    "lines[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the label &amp; message itself are separated by a `\\t` character on each line. \n",
    "Now let us read in all the lines into a `list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'), (0, 'Ok lar... Joking wif u oni...'), (1, \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"), (0, 'U dun say so early hor... U c already then say...'), (0, \"Nah I don't think he goes to usf, he lives around here though\")]\n"
     ]
    }
   ],
   "source": [
    "spam_dataset = []\n",
    "\n",
    "for line in lines:\n",
    "    label, text = line.split(\"\\t\")\n",
    "    if label.strip() == \"spam\":\n",
    "        spam_dataset.append((1, text.strip()))\n",
    "    else:\n",
    "        spam_dataset.append((0, text.strip()))\n",
    "print(spam_dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Spam                                            Message\n",
       "0     0  Go until jurong point, crazy.. Available only ...\n",
       "1     0                      Ok lar... Joking wif u oni...\n",
       "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3     0  U dun say so early hor... U c already then say...\n",
       "4     0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(spam_dataset, columns=[\"Spam\", \"Message\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def message_length(x):\n",
    "    return len(x)\n",
    "\n",
    "\n",
    "def num_capitals(x):\n",
    "    \"\"\"count # of capital letters in x (assuming x is an English sentence)\"\"\"\n",
    "    _, count = re.subn(r\"[A-Z]\", \"\", x)\n",
    "    return count\n",
    "\n",
    "\n",
    "def num_punctuation(x):\n",
    "    \"\"\"count # of punctuations in x\"\"\"\n",
    "    _, count = re.subn(r\"\\W\", \"\", x)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply these functions to the Dataframe\n",
    "df[\"Length\"] = df[\"Message\"].apply(message_length)\n",
    "df[\"Capitals\"] = df[\"Message\"].apply(num_capitals)\n",
    "df[\"Punctuations\"] = df[\"Message\"].apply(num_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Length</th>\n",
       "      <th>Capitals</th>\n",
       "      <th>Punctuations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5574.000000</td>\n",
       "      <td>5574.000000</td>\n",
       "      <td>5574.000000</td>\n",
       "      <td>5574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.134015</td>\n",
       "      <td>80.443488</td>\n",
       "      <td>5.621636</td>\n",
       "      <td>18.942591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.340699</td>\n",
       "      <td>59.841746</td>\n",
       "      <td>11.683233</td>\n",
       "      <td>14.825994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>910.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>253.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Spam       Length     Capitals  Punctuations\n",
       "count  5574.000000  5574.000000  5574.000000   5574.000000\n",
       "mean      0.134015    80.443488     5.621636     18.942591\n",
       "std       0.340699    59.841746    11.683233     14.825994\n",
       "min       0.000000     2.000000     0.000000      0.000000\n",
       "25%       0.000000    36.000000     1.000000      8.000000\n",
       "50%       0.000000    61.000000     2.000000     15.000000\n",
       "75%       0.000000   122.000000     4.000000     27.000000\n",
       "max       1.000000   910.000000   129.000000    253.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()  # display stats of all numeric cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model to classify sentiment based on the above info\n",
    "Let's build a model to classify sentiment based on the `length`, `num capitals` and `num punctuations` fields that we just added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (4459, 3) - y_train.shape: (4459, 1) - X_test.shape: (1115, 3) - y_test.shape: (1115, 1)\n"
     ]
    }
   ],
   "source": [
    "df2 = df[[\"Spam\", \"Length\", \"Capitals\", \"Punctuations\"]]\n",
    "\n",
    "# split into train/test sets\n",
    "train = df2.sample(frac=0.80, random_state=SEED)\n",
    "test = df2.drop(train.index)\n",
    "\n",
    "X_train = train[[\"Length\", \"Capitals\", \"Punctuations\"]]\n",
    "y_train = train[[\"Spam\"]]\n",
    "\n",
    "X_test = test[[\"Length\", \"Capitals\", \"Punctuations\"]]\n",
    "y_test = test[[\"Spam\"]]\n",
    "\n",
    "print(\n",
    "    f\"X_train.shape: {X_train.shape} - y_train.shape: {y_train.shape} - \"\n",
    "    f\"X_test.shape: {X_test.shape} - y_test.shape: {y_test.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_dim=3, num_units=12):\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(num_units, input_dim=input_dim, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                48        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "446/446 [==============================] - 4s 4ms/step - loss: 0.8960 - accuracy: 0.8704\n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 0.3108 - accuracy: 0.9184\n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 2s 3ms/step - loss: 0.2635 - accuracy: 0.9264\n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 0.2376 - accuracy: 0.9316\n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 0.2281 - accuracy: 0.9294\n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 0.2262 - accuracy: 0.9282\n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 0.2130 - accuracy: 0.9312\n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 0.2109 - accuracy: 0.9327\n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 2s 4ms/step - loss: 0.2084 - accuracy: 0.9320\n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 2s 5ms/step - loss: 0.2120 - accuracy: 0.9336\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, epochs=15, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([960, 155]), 1115)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test.values.ravel()), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 5ms/step - loss: 0.2095 - accuracy: 0.9345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20948441326618195, 0.9345291256904602]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test).ravel() >= 0.5).astype(np.int32)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnlp10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
